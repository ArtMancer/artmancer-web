[project]
name = "server"
version = "0.1.0"
description = "ArtMancer Web Server - Local Qwen Image Editing API"
readme = "README.md"
requires-python = ">=3.12"
dependencies = [
  "fastapi[standard]>=0.117.1",
  "pillow>=10.0.0",
  "python-multipart>=0.0.9",
  "pydantic>=2.0.0",
  "pydantic-settings>=2.6.0",
  "uvicorn[standard]>=0.30.0",
  "python-dotenv>=1.0.0",
  "requests>=2.31.0",
  # Torch sẽ được cài qua extras
  "diffusers>=0.35.1",
  "transformers>=4.56.2",
  "accelerate>=1.10.1",
  "hf-xet>=1.1.10",
  "huggingface-hub[cli]>=0.35.1",
  "numpy>=1.24.0",
  "safetensors>=0.4.0",
  "torchmetrics>=1.0.0",
  "scikit-image>=0.21.0",
  "ultralytics>=8.0.0",
  "opencv-python-headless>=4.11.0.86",
  "pandas>=2.3.3",
]

[project.optional-dependencies]
# CUDA 12.8
cuda = [
  "torch>=2.8.0",
  "torchvision>=0.23.0",
]

# Intel XPU
xpu = [
  "torch>=2.8.0",
  "torchvision>=0.23.0",
  "pytorch-triton-xpu",
]

# CPU only
cpu = [
  "torch>=2.8.0",
  "torchvision>=0.23.0",
]

# CLIP (common for all)
clip = [
  "clip @ git+https://github.com/openai/CLIP.git",
]

[[tool.uv.index]]
name = "pytorch-cu128"
url = "https://download.pytorch.org/whl/cu128"
explicit = true

[[tool.uv.index]]
name = "pytorch-xpu"
url = "https://download.pytorch.org/whl/xpu"
explicit = true

[tool.uv.sources]
# CUDA sources
torch = [
  # { index = "pytorch-cu128", marker = "extra == 'cuda'" },
  # We explicitly say: use xpu ONLY if cuda is NOT enabled
  { index = "pytorch-xpu", marker = "extra == 'xpu' and extra != 'cuda'" },
]
torchvision = [
  # { index = "pytorch-cu128", marker = "extra == 'cuda'" },
  { index = "pytorch-xpu", marker = "extra == 'xpu' and extra != 'cuda'" },
]
pytorch-triton-xpu = [
  { index = "pytorch-xpu", marker = "extra == 'xpu'" },
]
diffusers = { git = "https://github.com/huggingface/diffusers" }